{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LfpZcsvKXzc_"
      },
      "outputs": [],
      "source": [
        "from datasets import load_from_disk\n",
        "from transformers import (AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments)\n",
        "import evaluate\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pejXilMmX03-"
      },
      "outputs": [],
      "source": [
        "seed = 413\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVPsdHy7YKx1"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4JSt0nSYLpl"
      },
      "outputs": [],
      "source": [
        "inputs = {\"raw\": \"dialogue\", \"resolved\": \"resolved_text\"}\n",
        "data = load_from_disk(\"samsum_new\")\n",
        "model_checkpoint = \"t5-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQXgZqlcYc5V"
      },
      "outputs": [],
      "source": [
        "def preprocess(data, input):\n",
        "    inputs = data[input]\n",
        "    model_inputs = tokenizer(inputs, max_length=512, truncation=True)\n",
        "    labels = tokenizer(text_target=data[\"summary\"], max_length=128, truncation=True)\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F73Y-i5LYj0V"
      },
      "outputs": [],
      "source": [
        "rouge = evaluate.load(\"rouge\")\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    if isinstance(predictions, tuple):\n",
        "        predictions = predictions[0]\n",
        "    predictions = np.array(predictions)\n",
        "    predictions = predictions.astype(np.int64)\n",
        "    predictions = np.clip(predictions, 0, tokenizer.vocab_size - 1)\n",
        "    predictions = predictions.tolist()\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    if isinstance(labels, tuple):\n",
        "        labels = labels[0]\n",
        "    labels = np.array(labels)\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    labels = labels.astype(np.int64).tolist()\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "    return {k: round(v * 100, 4) for k, v in result.items()}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjAUa225YrNc",
        "outputId": "cd3c71e5-5562-4ed5-cc0e-f467ba6039a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 1.4028204679489136, 'eval_rouge1': 47.856, 'eval_rouge2': 23.9294, 'eval_rougeL': 40.0097, 'eval_rougeLsum': 40.0419, 'eval_runtime': 63.5825, 'eval_samples_per_second': 12.865, 'eval_steps_per_second': 1.62, 'epoch': 1.0}\n",
            "{'eval_loss': 2.844597578048706, 'eval_rouge1': 28.1794, 'eval_rouge2': 10.1408, 'eval_rougeL': 24.7284, 'eval_rougeLsum': 24.7015, 'eval_runtime': 61.5508, 'eval_samples_per_second': 13.29, 'eval_steps_per_second': 1.673, 'epoch': 2.0}\n",
            "{'eval_loss': 2.8258883953094482, 'eval_rouge1': 27.3721, 'eval_rouge2': 9.4496, 'eval_rougeL': 23.9784, 'eval_rougeLsum': 23.9712, 'eval_runtime': 62.4779, 'eval_samples_per_second': 13.093, 'eval_steps_per_second': 1.649, 'epoch': 3.0}\n",
            "{'train_runtime': 1709.0635, 'train_samples_per_second': 25.86, 'train_steps_per_second': 3.233, 'train_loss': 2.4396065191820484, 'epoch': 3.0}\n",
            "{'eval_loss': 2.8258883953094482, 'eval_rouge1': 27.3721, 'eval_rouge2': 9.4496, 'eval_rougeL': 23.9784, 'eval_rougeLsum': 23.9712, 'eval_runtime': 62.8648, 'eval_samples_per_second': 13.012, 'eval_steps_per_second': 1.638, 'epoch': 3.0}\n",
            "\n",
            "Metrics for raw input:\n",
            "Loss      : 2.8259\n",
            "ROUGE1    : 27.3721\n",
            "ROUGE2    : 9.4496\n",
            "ROUGEL    : 23.9784\n",
            "{'eval_loss': 1.6600048542022705, 'eval_rouge1': 41.2582, 'eval_rouge2': 18.4295, 'eval_rougeL': 34.7905, 'eval_rougeLsum': 34.7825, 'eval_runtime': 63.7581, 'eval_samples_per_second': 12.83, 'eval_steps_per_second': 1.615, 'epoch': 1.0}\n",
            "{'eval_loss': 1.6586564779281616, 'eval_rouge1': 41.3287, 'eval_rouge2': 18.2517, 'eval_rougeL': 34.6683, 'eval_rougeLsum': 34.6629, 'eval_runtime': 63.4911, 'eval_samples_per_second': 12.884, 'eval_steps_per_second': 1.622, 'epoch': 2.0}\n",
            "{'eval_loss': 1.6585246324539185, 'eval_rouge1': 41.3422, 'eval_rouge2': 18.2445, 'eval_rougeL': 34.6729, 'eval_rougeLsum': 34.6824, 'eval_runtime': 63.9489, 'eval_samples_per_second': 12.791, 'eval_steps_per_second': 1.611, 'epoch': 3.0}\n",
            "{'train_runtime': 1747.1417, 'train_samples_per_second': 25.296, 'train_steps_per_second': 3.163, 'train_loss': 1.8202320917594101, 'epoch': 3.0}\n",
            "{'eval_loss': 1.6585246324539185, 'eval_rouge1': 41.3422, 'eval_rouge2': 18.2445, 'eval_rougeL': 34.6729, 'eval_rougeLsum': 34.6824, 'eval_runtime': 63.8123, 'eval_samples_per_second': 12.819, 'eval_steps_per_second': 1.614, 'epoch': 3.0}\n",
            "\n",
            "Metrics for resolved input:\n",
            "Loss      : 1.6585\n",
            "ROUGE1    : 41.3422\n",
            "ROUGE2    : 18.2445\n",
            "ROUGEL    : 34.6729\n"
          ]
        }
      ],
      "source": [
        "for version, input_ in inputs.items():\n",
        "\n",
        "    tokenized_data = data.map(lambda x: preprocess(x, input_), batched=True, remove_columns=data[\"train\"].column_names)\n",
        "\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint).to(device)\n",
        "    for name, param in model.named_parameters():\n",
        "        if any(f\"encoder.block.{i}.\" in name for i in range(3)):\n",
        "          param.requires_grad = False\n",
        "\n",
        "    training_args = Seq2SeqTrainingArguments(\n",
        "        output_dir=f\"/content/t5-base-{version}-finetuned\",\n",
        "        eval_strategy=\"epoch\",\n",
        "        learning_rate=0.0001,\n",
        "        per_device_train_batch_size=8,\n",
        "        per_device_eval_batch_size=8,\n",
        "        weight_decay=0.01,\n",
        "        save_total_limit=1,\n",
        "        num_train_epochs=3,\n",
        "        predict_with_generate=True,\n",
        "        fp16=True,\n",
        "        push_to_hub=False,\n",
        "        logging_dir=f\"/content/logs-{version}\",\n",
        "        logging_strategy=\"no\",\n",
        "        logging_steps=1000000,\n",
        "        report_to=\"none\",\n",
        "    )\n",
        "\n",
        "    data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
        "\n",
        "    trainer = Seq2SeqTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_data[\"train\"],\n",
        "        eval_dataset=tokenized_data[\"validation\"],\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    trainer.save_model(f\"/content/t5-base-{version}-finetuned\")\n",
        "\n",
        "    metrics = trainer.evaluate()\n",
        "\n",
        "    print(f\"\\nMetrics for {version} input:\")\n",
        "    for key in [\"eval_loss\", \"eval_rouge1\", \"eval_rouge2\", \"eval_rougeL\"]:\n",
        "        label_map = {\n",
        "            \"eval_loss\": \"Loss\",\n",
        "            \"eval_rouge1\": \"ROUGE1\",\n",
        "            \"eval_rouge2\": \"ROUGE2\",\n",
        "            \"eval_rougeL\": \"ROUGEL\",\n",
        "        }\n",
        "        if key in metrics:\n",
        "            print(f\"{label_map[key]:<10}: {metrics[key]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPhc3gEyU5dV"
      },
      "outputs": [],
      "source": [
        "def summary(sample_idx, data, model, tokenizer, model_resolved, tokenizer_resolved, device):\n",
        "    text = data[\"test\"][sample_idx][\"dialogue\"]\n",
        "    resolved_text = data[\"test\"][sample_idx][\"resolved_text\"]\n",
        "    reference = data[\"test\"][sample_idx][\"summary\"]\n",
        "\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
        "    output = model.generate(**inputs, max_length=128)\n",
        "    summary = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "    inputs_resolved = tokenizer_resolved(resolved_text, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
        "    output_resolved = model_resolved.generate(**inputs_resolved, max_length=128)\n",
        "    summary_resolved = tokenizer_resolved.decode(output_resolved[0], skip_special_tokens=True)\n",
        "\n",
        "    print(\"Input\")\n",
        "    print(text)\n",
        "    print()\n",
        "    print(\"Summary from Raw Model\")\n",
        "    print(summary)\n",
        "    print()\n",
        "    print(\"Summary from Anaphora Resolution Model\")\n",
        "    print(summary_resolved)\n",
        "    print()\n",
        "    print(\"Reference Summary\")\n",
        "    print(reference)\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LftiM-C6XnIb"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/t5-base-raw-finetuned\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"/content/t5-base-raw-finetuned\").to(device)\n",
        "\n",
        "tokenizer_resolved = AutoTokenizer.from_pretrained(\"/content/t5-base-resolved-finetuned\")\n",
        "model_resolved = AutoModelForSeq2SeqLM.from_pretrained(\"/content/t5-base-resolved-finetuned\").to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8MF2eifa7WE",
        "outputId": "19ca575a-1b41-409b-bb15-3b8ccc5a4a60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input\n",
            "Igor: Shit, I've got so much to do at work and I'm so demotivated. \r\n",
            "John: It's pretty irresponsible to give that much work to someone on their notice period.\r\n",
            "Igor: Yeah, exactly! Should I even care?\r\n",
            "John: It's up to you, but you know what they say...\r\n",
            "Igor: What do you mean?\r\n",
            "John: Well, they say how you end things shows how you really are...\r\n",
            "Igor: And now how you start, right?\r\n",
            "John: Gotcha! \r\n",
            "Igor: So what shall I do then? \r\n",
            "John: It's only two weeks left, so grit your teeth and do what you have to do. \r\n",
            "Igor: Easy to say, hard to perform.\r\n",
            "John: Come on, stop thinking, start doing! \r\n",
            "Igor: That's so typical of you!  ;)  \n",
            "\n",
            "Summary from Raw Model\n",
            "John has been working for his job.\n",
            "\n",
            "Summary from Anaphora Resolution Model\n",
            "Igor has two weeks left to finish work.\n",
            "\n",
            "Reference Summary\n",
            "Igor has a lot of work on his notice period and he feels demotivated. John thinks he should do what he has to do nevertheless. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "summary(\n",
        "    sample_idx=17,\n",
        "    data=data,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    model_resolved=model_resolved,\n",
        "    tokenizer_resolved=tokenizer_resolved,\n",
        "    device=device\n",
        ")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
